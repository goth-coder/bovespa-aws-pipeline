# ğŸš€ Pipeline Batch Bovespa - AWS

## ğŸ“œ Sobre o Projeto
Este projeto tem como objetivo construir um **pipeline de dados batch** para ingestÃ£o, processamento e anÃ¡lise dos dados do pregÃ£o da **B3**, utilizando serviÃ§os da **AWS** (S3, Glue, Lambda, Athena).  
O pipeline serÃ¡ responsÃ¡vel por realizar o **scraping** dos dados da B3, armazenar em um **Data Lake** no formato **Parquet**, processar via **AWS Glue** e disponibilizar para consulta no **AWS Athena**.

**Status:** ğŸš§ Em desenvolvimento - Estrutura modular implementada

---

## ğŸ—ï¸ Estrutura do Projeto

```
bovespa-aws-pipeline/
â”œâ”€â”€ ğŸ“ src/                          # CÃ³digo fonte principal
â”‚   â””â”€â”€ ğŸ“ scraping/                 # MÃ³dulo de coleta de dados
â”‚       â”œâ”€â”€ scraping.py              # Script principal de scraping
â”‚       â”œâ”€â”€ config.py                # ConfiguraÃ§Ãµes e URLs
â”‚       â”œâ”€â”€ utils.py                 # FunÃ§Ãµes auxiliares
â”‚       â””â”€â”€ __init__.py              # InicializaÃ§Ã£o do mÃ³dulo
â”œâ”€â”€ ğŸ“ data/                         # Dados locais
â”‚   â””â”€â”€ ğŸ“ raw/                      # Dados brutos do scraping
â”‚       â”œâ”€â”€ b3_carteira_dia_setor.json
â”‚       â”œâ”€â”€ b3_carteira_dia_codigo.json
â”‚       â”œâ”€â”€ b3_carteira_teorica_mai_ago_2025.json
â”‚       â”œâ”€â”€ b3_previa_quadrimestral_set_dez_2025.json
â”‚       â””â”€â”€ b3_dados_consolidados.json
â”œâ”€â”€ ğŸ“ docs/                         # DocumentaÃ§Ã£o e controle
â”‚   â”œâ”€â”€ kanban_de_progresso.md       # Status das tarefas
â”‚   â””â”€â”€ log_de_tarefas.md           # Log de atividades
â”œâ”€â”€ ğŸ“ .github/                      # ConfiguraÃ§Ãµes GitHub
â”‚   â””â”€â”€ copilot-instructions.md      # InstruÃ§Ãµes para agentes
â”œâ”€â”€ test_modular.py                  # Script de teste da estrutura
â”œâ”€â”€ main.py                         # Script original (depreciado)
â”œâ”€â”€ requirements.txt                # DependÃªncias Python
â””â”€â”€ README.md                       # Este arquivo
```

---

## ğŸ›  Tecnologias Utilizadas
- Python (para scraping e Lambda)
- AWS S3 (armazenamento Data Lake)
- AWS Lambda (orquestraÃ§Ã£o do Glue)
- AWS Glue (ETL visual)
- AWS Athena (consulta SQL)
- Formato Parquet (dados otimizados)

---

## ğŸ“‹ Checklist do Projeto

### **Coleta de Dados**
- [x] âœ… Criar script de **scraping** para coletar dados do pregÃ£o da B3
- [x] âœ… Implementar **4 endpoints**: Carteira do Dia (setor/cÃ³digo), Carteira TeÃ³rica, PrÃ©via Quadrimestral
- [x] âœ… Estrutura modular com `src/scraping/`
- [x] âœ… Coleta de ~339 aÃ§Ãµes por execuÃ§Ã£o
- [ ] Converter dados para **Parquet**
- [ ] Adicionar **partiÃ§Ã£o diÃ¡ria** ao salvar

### **Armazenamento no S3**
- [ ] Criar bucket S3
- [ ] Estruturar pastas `/raw/` e `/refined/`
- [ ] Configurar upload automÃ¡tico do scraping para `/raw/`

### **OrquestraÃ§Ã£o com AWS Lambda**
- [ ] Criar funÃ§Ã£o Lambda
- [ ] Configurar gatilho de evento **S3 â†’ Lambda**
- [ ] Lambda iniciar execuÃ§Ã£o do Job Glue

### **Processamento com AWS Glue**
- [ ] Criar Job ETL no modo visual
- [ ] Implementar transformaÃ§Ãµes obrigatÃ³rias:
  - [ ] Agrupamento numÃ©rico (sumarizaÃ§Ã£o, contagem ou soma)
  - [ ] Renomear 2 colunas
  - [ ] CÃ¡lculo com campos de data
- [ ] Salvar dados refinados no S3 `/refined/`
- [ ] Particionar por **data** e **nome/abreviaÃ§Ã£o da aÃ§Ã£o**
- [ ] Catalogar dados no Glue Catalog

### **Consulta e ValidaÃ§Ã£o**
- [ ] Consultar dados no AWS Athena
- [ ] Validar partiÃ§Ãµes e formato
- [ ] (Opcional) Criar Notebook no Athena com visualizaÃ§Ã£o grÃ¡fica

---

## ğŸ“‚ Estrutura do Projeto
```bash
bovespa-aws-pipeline/
â”œâ”€â”€ ğŸ“ scraping/           # Scripts de coleta de dados da B3
â”‚   â”œâ”€â”€ bovespa_scraper.py    # Scraper principal com conversÃ£o para Parquet
â”‚   â””â”€â”€ README.md             # DocumentaÃ§Ã£o do mÃ³dulo
â”‚
â”œâ”€â”€ ğŸ“ lambda/             # FunÃ§Ã£o AWS Lambda para orquestraÃ§Ã£o
â”‚   â”œâ”€â”€ lambda_function.py    # Detecta S3 events e dispara Glue Job
â”‚   â”œâ”€â”€ requirements.txt      # DependÃªncias da Lambda
â”‚   â””â”€â”€ README.md             # DocumentaÃ§Ã£o da Lambda
â”‚
â”œâ”€â”€ ğŸ“ glue/               # ConfiguraÃ§Ãµes do AWS Glue ETL
â”‚   â”œâ”€â”€ glue_job_helper.py    # Helpers e configuraÃ§Ãµes do Job
â”‚   â””â”€â”€ README.md             # DocumentaÃ§Ã£o das transformaÃ§Ãµes
â”‚
â”œâ”€â”€ ğŸ“ config/             # ConfiguraÃ§Ãµes centralizadas
â”‚   â”œâ”€â”€ settings.py           # ConfiguraÃ§Ãµes Python
â”‚   â””â”€â”€ .env.example          # Exemplo de variÃ¡veis de ambiente
â”‚
â”œâ”€â”€ ğŸ“ scripts/            # Scripts de automaÃ§Ã£o e deploy
â”‚   â”œâ”€â”€ deploy_aws.py         # Deploy automÃ¡tico da infraestrutura
â”‚   â””â”€â”€ run_local_test.py     # Testes locais e scraping
â”‚
â”œâ”€â”€ ğŸ“ tests/              # Testes unitÃ¡rios e de integraÃ§Ã£o
â”‚   â”œâ”€â”€ test_scraping.py      # Testes do mÃ³dulo de scraping
â”‚   â””â”€â”€ README.md             # DocumentaÃ§Ã£o dos testes
â”‚
â”œâ”€â”€ ğŸ“ docs/               # DocumentaÃ§Ã£o tÃ©cnica
â”‚   â”œâ”€â”€ architecture.md       # Arquitetura detalhada
â”‚   â””â”€â”€ deploy.md             # Guia completo de deploy
â”‚
â”œâ”€â”€ ğŸ“ infrastructure/     # Infrastructure as Code (Terraform)
â”‚   â””â”€â”€ main.tf               # DefiniÃ§Ã£o completa da infraestrutura AWS
â”‚
â”œâ”€â”€ ğŸ“„ QUICKSTART.md       # Guia de inÃ­cio rÃ¡pido
â”œâ”€â”€ ğŸ“„ pyproject.toml      # ConfiguraÃ§Ã£o do projeto Python
â”œâ”€â”€ ğŸ“„ requirements.txt    # DependÃªncias Python
â””â”€â”€ ğŸ“„ .gitignore          # Arquivos ignorados pelo Git
```
## ï¿½ Quick Start

```bash
# 1. Instalar dependÃªncias
pip install -r requirements.txt

# 2. Configurar AWS
aws configure

# 3. Configurar projeto
cp config/.env.example config/.env

# 4. Testar localmente
python scripts/run_local_test.py --action test

# 5. Deploy da infraestrutura
cd infrastructure/ && terraform apply
```

ğŸ“– **Guia completo**: [QUICKSTART.md](QUICKSTART.md)

---
Fluxo esperado:
1. Scraping coleta dados da B3
2. Salva no S3 /raw/ em Parquet (partiÃ§Ã£o diÃ¡ria)
3. Evento S3 aciona AWS Lambda
4. Lambda dispara Job Glue
5. Glue processa dados e salva no S3 /refined/
6. Glue Catalog atualiza tabela
7. Consulta no Athena

## ğŸ“œ LicenÃ§a
Este projeto Ã© de uso acadÃªmico para o Tech Challenge de Big Data Architecture.